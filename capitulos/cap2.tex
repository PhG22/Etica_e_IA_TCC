\chapter{A Concepção do Objeto Técnico}\label{cap:concepcao_obj_tecnico}

Este capítulo constrói o alicerce teórico para a análise crítica do desenvolvimento de software e da Inteligência Artificial proposta na introdução. 
O objetivo é desmistificar 
o conceito de "concepção de objeto", argumentando que, mesmo nos sistemas de IA mais complexos, a concepção permanece um ato deliberado, consciente e político do sujeito humano, 
que inscreve sua finalidade em um objeto técnico passivo. 
A aparente autonomia da IA não é uma superação da dialética sujeito-objeto, mas sim sua mais sofisticada forma de 
ocultamento. 
Será analisado como a finalidade humana é traduzida em um "roteiro" probabilístico, como esse processo é moldado por relações de poder e, crucialmente, como a 
narrativa de "agência da IA" funciona como uma manobra ideológica para obscurecer o poder corporativo e o trabalho humano, em um paralelo direto com a crítica de Álvaro Vieira 
Pinto à "tecno-estrutura". 

\section{O Trabalho como Fundamento da Técnica e da Hominização}\label{sec:trabalho_como_fundamento}

Para compreender a "concepção de objeto" no contexto tecnológico, é imperativo primeiro estabelecer uma base filosófica que transcenda a mera noção de design ou projeto. 
A concepção de qualquer artefato técnico está fundamentalmente enraizada no conceito de trabalho. 
Na tradição do materialismo histórico, o trabalho não é apenas uma atividade 
econômica, mas a própria essência da atividade humana, o processo pelo qual o ser humano transforma a natureza para satisfazer suas necessidades e, ao fazê-lo, transforma a si 
mesmo e constrói sua identidade. 
É através do trabalho que a humanidade se distingue dos outros seres, criando cultura, sociedade e história. 

Álvaro Vieira Pinto \cite{VieiraPinto2005}, alinhado a essa perspectiva materialista, concebe a técnica não como algo externo ao homem, mas como uma extensão dialética de seu próprio ser. 
A técnica 
emerge do trabalho como uma mediação entre o homem e a natureza, um prolongamento de suas capacidades físicas e intelectuais que permite um domínio crescente sobre o mundo 
objetivo. 
Nesta visão, a concepção de um objeto técnico não é um ato puramente intelectual ou abstrato, mas uma forma de práxis: a união indissolúvel entre teoria e prática, 
pensamento e ação. 
Conceber um objeto é, portanto, um ato fundamental de hominização, um exercício da capacidade humana de projetar no mundo uma intenção e materializá-la 
através da ação transformadora. 

\section{A Dialética do Sujeito e do Objeto}\label{sec:dialetica}

Na filosofia da tecnologia de Álvaro Vieira Pinto \cite{VieiraPinto2005}, a dialética introduzida anteriormente é o ponto de partida para desmistificar a tecnologia e situá-la em seu devido lugar, como 
um produto da existência humana e não como uma força autônoma. 
O ser humano, para Vieira Pinto, é o único sujeito atuante. 
É um ser histórico, dotado de consciência, que se depara com as contradições de sua existência, a necessidade de se 
abrigar, de se alimentar, de se comunicar, e as resolve através do trabalho. 
O trabalho não é apenas uma atividade econômica, mas a própria essência da atividade humana, o 
processo pelo qual o ser humano transforma a natureza para satisfazer suas necessidades e, ao fazê-lo, transforma a si mesmo e constrói sua identidade. 
A técnica e a tecnologia 
emergem precisamente desta ação transformadora sobre o mundo. 
A capacidade de fabricar uma ferramenta, por mais simples ou avançada que seja, é uma expressão da racionalidade 
humana que busca expandir suas próprias capacidades para mediar sua relação com o mundo objetivo. 

Em contrapartida, a máquina é, e sempre será, um objeto. Ela é uma mediação, uma extensão da capacidade humana. 
Vieira Pinto é enfático ao afirmar que "a máquina não trabalha". 
Trabalhar é uma atividade existencial, intrinsecamente ligada a uma finalidade produzida por uma consciência, algo que a máquina não possui. 
Ela pode executar efeitos dinâmicos, 
processar informações e produzir resultados, mas o faz como um instrumento passivo, seguindo o programa que lhe foi "embutido pelo seu criador, o cérebro humano". 
A máquina não tem "necessidade própria" para agir, sua ação é a "concretização da necessidade de outro alguém". 

A aplicação direta desta dialética à Inteligência Artificial é fundamental. 
A "inteligência" de um sistema de IA não é uma propriedade intrínseca do objeto, mas a 
"exteriorização e a multiplicação da racionalidade do sujeito que o concebeu". 
O aperfeiçoamento dos algoritmos não representa uma evolução da máquina em si, mas sim uma 
evolução do pensamento humano que, ao apreender as leis da lógica e da natureza, descobre como construir dispositivos mais potentes para mediar sua relação com o mundo. 
Esta distinção filosófica serve como a principal ferramenta analítica para desmontar a noção de "inteligência artificial" como uma forma de agência. 
A "inteligência" do sistema 
é a inteligência de seu criador, cristalizada e operacionalizada no objeto. 


O discurso popular e corporativo sobre IA, no entanto, frequentemente inverte essa relação fundamental, tratando a máquina como um sujeito, usando de falas como 
"A IA aprendeu" e "O algoritmo decidiu". 
Essa inversão não é um erro linguístico inocente, é o primeiro passo de uma sofisticada mistificação ideológica. 
Ao antropomorfizar o 
objeto, esvazia-se a responsabilidade do sujeito humano, o engenheiro, a corporação, o investidor. 
Se a máquina é o sujeito que "decide", então o criador humano é absolvido da 
responsabilidade pelas consequências dessa decisão, sejam elas vieses discriminatórios, desinformação ou danos sociais. 
A própria linguagem usada para descrever a IA torna-se 
um campo de batalha ideológico, preparando o terreno para o ocultamento do poder e do trabalho que sustentam o sistema. 

\section{A Natureza do Objeto Técnico}\label{sec:natureza_obj_tec}

A visão comum da tecnologia tende a reduzi-la a um conjunto de ferramentas neutras, cujo valor, bom ou mau, dependeria exclusivamente do uso que se faz delas. 
A Teoria Crítica 
da Tecnologia, notadamente na obra de Andrew Feenberg \cite{Feenberg1999}, desafia frontalmente essa concepção instrumentalista. 
Feenberg argumenta que a tecnologia nunca é neutra, ela é, em si, 
um palco de valores sociais, políticos e éticos. 
Todo artefato técnico, de um martelo a um algoritmo, possui o que ele denomina um "código técnico", um conjunto de regras e 
pressupostos embutidos em seu design que refletem e reforçam uma determinada visão de mundo e específicas relações de poder. 

A tecnologia, para Feenberg, é ambivalente. Seu design é subdeterminado pela pura eficiência técnica, o que significa que, para uma mesma função, existem múltiplas possibilidades 
de design, cada uma favorecendo diferentes interesses e valores sociais. 
Um sistema de produção pode ser desenhado para maximizar o controle gerencial e a desqualificação do 
trabalhador, ou, alternativamente, para ampliar a autonomia e a habilidade do operário. 
Ambas as soluções podem ser tecnicamente viáveis, mas a escolha entre elas é política. 
Portanto, a análise de um objeto técnico exige que se questione não apenas "para que serve?", mas também "quais valores estão inscritos em seu design?" 
e "quais relações sociais 
ele promove ou inibe?". 

\section{A Inscrição da Finalidade do Código Técnico ao Roteiro Probabilístico}\label{sec:inscricao_finalidade}

Em sistemas computacionais tradicionais, a finalidade é explicitada em linhas de código e algoritmos lógicos. 
Contudo, nos sistemas de Inteligência Artificial, como os Modelos 
de Linguagem Massivos, os \textit{LLMs}, a inscrição da finalidade assume uma forma radicalmente diferente, ela se materializa como um "roteiro" estatístico, uma vasta paisagem 
probabilística moldada por seus criadores. 
Estudos sobre o funcionamento de \textit{LLMs} descrevem estes sistemas como "papagaios estocásticos" \cite{Bender2021} que, em vez de compreenderem a linguagem, 
recombinam textos existentes para gerar "colagens" com base em probabilidades inferidas. 
O processo de treinamento visa a prever o próximo "\textit{token}", uma palavra ou parte de uma, 
a partir de um texto de entrada, com base nos padrões estatísticos de um imenso corpus de dados. 
O comportamento do modelo não é guiado por regras lógicas ou uma compreensão 
semântica, mas pela navegação em um espaço de probabilidades definido por seus dados de treinamento, sua arquitetura e os processos de alinhamento com preferências humanas. 

Neste contexto, o "roteiro" que governa a IA é a totalidade desse universo estatístico. 
O ato de "conceber" um \textit{LLM} e de lhe atribuir uma finalidade, como "ser um assistente 
prestativo", torna-se, em grande medida, o ato de selecionar, curar e estruturar os dados que formarão seu "mundo". 
A decisão de treinar um modelo predominantemente com dados 
de programação do \textit{Stack Overflow}, por exemplo, inscreve nele a finalidade de ser um assistente de codificação. 
A exclusão de certos tipos de texto ou a inclusão de exemplos 
específicos durante o alinhamento são atos de engenharia que moldam a paisagem probabilística para que as respostas mais prováveis do modelo se alinhem com o propósito desejado. 
Assim, o conceito filosófico de finalidade se materializa no campo técnico da IA não como um comando determinístico, mas como a arquitetura de um vasto espaço de possibilidades. 
O sistema de IA não "entende" seu propósito, ele simplesmente segue os gradientes de probabilidade que seus criadores humanos estabeleceram. 

A natureza do "código técnico" de um \textit{LLM}, por ser estatístico e distribuído em bilhões de parâmetros, é inerentemente opaca e inescrutável, diferentemente do código de um 
artefato mecânico ou de um software tradicional. 
Essa opacidade não é apenas um desafio técnico, o chamado "problema da caixa-preta", mas uma poderosa ferramenta ideológica. 
Ela permite que as decisões e valores embutidos no modelo sejam apresentados como resultados "objetivos" e "emergentes" do processo estatístico, em vez de escolhas deliberadas 
de seus criadores. 
Vieses e resultados problemáticos podem ser atribuídos à "natureza dos dados" ou à "complexidade do modelo", em vez de às escolhas feitas durante a curadoria 
de dados e o alinhamento. 
A ideologia é, assim, "lavada" através da estatística, transformando decisões políticas em resultados aparentemente neutros e técnicos. 
Trata-se de 
uma forma avançada de reificação, onde as relações sociais e as escolhas humanas se solidificam em um objeto que parece ter vida própria. 

\section{A Concepção como Arena Sociopolítica}\label{sec:concepcao_arena_sociopolitica}

A concepção de um objeto técnico não ocorre em um vácuo. 
Ela está imersa em contextos sociais, culturais e políticos que moldam sua forma, função e significado. 
Abordagens 
teóricas como a Construção Social da Tecnologia (\textit{SCOT}), desenvolvida por Wiebe Bijker e Trevor Pinch \cite{BijkerPinch1989}, opõem-se ao determinismo tecnológico, a ideia de que a tecnologia se 
desenvolve de forma autônoma e linear, ditando as transformações sociais. 
Em vez disso, a \textit{SCOT} argumenta que a tecnologia é socialmente construída. 
Seu design e seus usos são 
negociados e contestados por diferentes "grupos sociais relevantes", produtores, usuários, reguladores, entre outros, e os artefatos resultantes inevitavelmente incorporam os valores 
de seus criadores e da sociedade em que surgem. 
Um artefato possui "flexibilidade interpretativa", significando que diferentes grupos o interpretam de maneiras distintas, o que 
leva a diferentes problemas e soluções de design. 

A concepção de sistemas de IA é um exemplo paradigmático desse processo. A finalidade inscrita nesses objetos não é neutra,
ela reflete e serve aos interesses dominantes que 
financiam e dirigem seu desenvolvimento. 
A própria monografia aponta para as "tecnopolíticas que perpassam a IA", como a "imposição de acumular infinitamente mais dados" para 
satisfazer a "necessidade de crescimento do capital" e a criação de uma "fachada que obscurece o trabalho humano" por trás da automação. 
Essas não são consequências acidentais 
da tecnologia, mas finalidades deliberadas, inscritas em seu design desde o início. 
A concepção de muitos sistemas de IA em larga escala é guiada por uma lógica de extração, 
onde a necessidade de vastos conjuntos de dados impulsiona um modelo de negócios baseado na vigilância e na comoditização da experiência humana. 

O processo de alinhamento de modelos, como o \textit{Reinforcement Learning from Human Feedback - RLHF}, é um ponto-chave de inscrição de valores e uma arena de negociação social. 
Nesse processo, o \textit{feedback} humano, na forma de classificações e preferências sobre as respostas do modelo, é usado para treinar um "modelo de recompensa". 
Esse modelo, 
por sua vez, guia o ajuste fino do \textit{LLM}, ensinando-o a produzir resultados que se alinhem com as preferências humanas codificadas. 
O que parece ser um processo técnico de 
otimização é, na verdade, um mecanismo para traduzir normas sociais e objetivos corporativos em sinais de recompensa que moldam a paisagem probabilística do modelo. 

Crucialmente, todo esse processo de concepção e alinhamento depende de múltiplas camadas de trabalho humano, muitas vezes invisibilizado. 
O \textit{RLHF} requer que trabalhadores 
humanos gerem respostas de demonstração e classifiquem as saídas do modelo. 
Antes mesmo disso, os vastos conjuntos de dados usados no pré-treinamento precisam ser coletados, 
limpos, rotulados e moderados por um exército global de "trabalhadores fantasma" (\textit{ghost workers}) \cite{GraySuri2019}, frequentemente em condições precárias. 
Relatos investigativos sobre empresas 
como \textit{Sama} e \textit{Scale AI}, que fornecem serviços de anotação de dados para gigantes da tecnologia, revelam um sistema de trabalho fragmentado, mal remunerado e 
psicologicamente desgastante, essencial para treinar sistemas como o \textit{ChatGPT}. 
Portanto, a concepção do objeto de IA não é um ato limpo de engenharia, mas um processo social 
complexo e estratificado, dependente de uma cadeia global de trabalho humano que é sistematicamente ocultada. 

\section{A Mistificação do Objeto}\label{sec:mistificacao_obj}

A tendência de atribuir agência e inteligência autônoma à tecnologia não é um fenômeno novo, mas uma manobra ideológica recorrente que serve para ocultar as verdadeiras relações 
de poder. 
A crítica de Álvaro Vieira Pinto \cite{VieiraPinto2005} ao conceito de "tecno-estrutura" de John K. Galbraith oferece um análogo histórico preciso para compreender a mistificação 
contemporânea da Inteligência Artificial. 

Galbraith argumentava que, na empresa industrial moderna, o poder havia se deslocado dos proprietários do capital para um novo grupo, a "tecno-estrutura", composta por técnicos 
e especialistas que detinham o "conhecimento organizado". 
Vieira Pinto desmonta essa noção como um "sofisma ideológico" e uma "escamoteação" que mascara a dominação inalterada 
do capital. 
Para ele, o conhecimento dos técnicos, longe de ser uma fonte de poder autônomo, é tratado como uma "mercadoria" que os capitalistas compram no mercado.
Os 
especialistas tornam-se trabalhadores intelectuais assalariados, moralmente rebaixados e despojados de sua liberdade criadora, transformados em "homens previsíveis" e peças 
anônimas de uma engrenagem cujo controle real permanece nas mãos dos donos do capital. 
A função ideológica da tecno-estrutura é dar uma aparência de racionalidade e 
democratização ao capitalismo, fazendo o poder "aparecer falsamente em outro lugar" para protegê-lo da "odiosidade popular".

A narrativa contemporânea sobre a "inteligência" e a "agência" da IA desempenha exatamente a mesma função ideológica, de forma ainda mais potente. 
Ao atribuir a capacidade de 
decisão, criação e aprendizado à própria máquina, desvia-se a atenção dos verdadeiros agentes, as corporações que detêm a propriedade dos modelos, da infraestrutura 
computacional e dos dados, e que os controlam para seus próprios fins de lucro e poder. 
A IA torna-se a nova tecno-estrutura, uma fachada de objetividade técnica que oculta as 
relações de produção e dominação. 

Essa mistificação é crucial para um segundo objetivo, tornar invisível o vasto contingente de trabalho humano que sustenta o sistema.
O "trabalho fantasma" (\textit{ghost work}) \cite{GraySuri2019} 
dos milhões de trabalhadores de plataforma que rotulam dados, moderam conteúdo e corrigem os erros dos algoritmos é a base material sobre a qual a ilusão de autonomia da máquina 
é erigida. 
A máquina parece "inteligente" precisamente porque o trabalho de inteligência de incontáveis seres humanos foi abstraído, fragmentado, precarizado e "codificado em sua 
estrutura probabilística". 
A IA, portanto, representa a culminação da lógica que Vieira Pinto criticou, ela não apenas oculta o 
poder, mas o faz através de um objeto que parece 
neutro e supra-humano, tornando a manobra ideológica mais eficaz e difícil de desmascarar. 

\section{A Reafirmação da Agência Humana na Lei e no Trabalho}\label{sec:reafirmacao_agencia_humana}

A crescente opacidade e o poder dos sistemas de IA, alimentados pelo discurso de sua autonomia, provocaram uma reação social e institucional que busca reafirmar a centralidade 
e a responsabilidade humanas. 
Este movimento, visível tanto na esfera regulatória quanto nas lutas trabalhistas, representa uma contestação prática da mistificação do objeto e 
uma tentativa de codificar legal e socialmente a distinção filosófica de Vieira Pinto entre o sujeito humano e o objeto técnico. 
A concepção do objeto não é apenas um ato 
técnico, mas um campo de batalha social onde a agência humana é defendida. 

Na esfera regulatória, o \textit{AI Act} da União Europeia \cite{EU_AI_Act2024} e o Projeto de Lei 2338/2023 no Brasil \cite{Brasil_PL2338} são exemplos proeminentes dessa reafirmação. 
Ao adotarem uma "abordagem baseada 
em risco" e exigirem "supervisão humana efetiva" para sistemas de alto risco, essas legislações posicionam a IA como uma ferramenta poderosa que deve, no entanto, permanecer sob 
o controle humano. 
Fundamentos como a "centralidade da pessoa humana" e princípios como a "participação humana no ciclo da inteligência artificial" no PL brasileiro buscam 
garantir legalmente que a responsabilidade final por danos ou decisões críticas recaia sobre os fornecedores e operadores humanos, e não sobre o sistema supostamente autônomo. 
Essas leis são, em essência, tentativas de restabelecer o ser humano como o sujeito soberano e a IA como o objeto que serve aos seus propósitos, forçando a transparência e a 
prestação de contas onde a ideologia da "caixa-preta" busca a isenção. 

No campo do trabalho criativo, a luta pela definição do sujeito é ainda mais explícita. 
A greve de 2023 da \textit{Writers Guild of America - WGA} foi um marco histórico. 
Ao 
negociar o Acordo Básico Mínimo (\textit{MBA}) de 2023 \cite{WGA_MBA2023}, os roteiristas garantiram cláusulas que estipulam que a IA não pode ser considerada uma "escritora" e que material gerado por IA 
não pode ser tratado como "material de origem" para fins de crédito ou remuneração. 
Esta foi uma vitória crucial na defesa do status dos roteiristas como sujeitos criadores, 
relegando a IA à sua posição correta de ferramenta. 
Eles lutaram para que a concepção da obra, o ato de criação, permanecesse uma prerrogativa humana. 
Este mesmo conflito ecoa 
no debate jurídico sobre direitos autorais, onde a tradição legal ancora a autoria na "criação do espírito humano", um conceito que sistemas de IA, por definição, não podem 
satisfazer. 

Essas ações regulatórias e trabalhistas não são meras reações a uma tecnologia já consolidada, 
elas participam ativamente de sua construção social. Utilizando a terminologia da 
teoria \textit{SCOT}, essas intervenções podem ser vistas como tentativas de "grupos sociais relevantes", cidadãos representados por legisladores, trabalhadores representados por 
sindicatos, entre outros, de forçar um "mecanismo de fechamento" na "flexibilidade interpretativa" da IA. 
Enquanto as corporações de tecnologia promovem a interpretação da 
"IA como agente" para maximizar seu poder e diluir sua responsabilidade, a sociedade civil reage para impor a interpretação da "IA como ferramenta sob controle humano". 
As leis 
e os contratos coletivos tornam-se, assim, os documentos onde a sociedade formaliza sua compreensão da relação entre humanos e tecnologia, forçando a reafirmação da agência e da 
responsabilidade humana contra a narrativa de autonomia da máquina. 
Eles são a prova de que a dialética sujeito-objeto é o cerne da política tecnológica contemporânea. 

\section{Consciência Crítica na Concepção}\label{sec:consciencia_critica_concepcao}

A análise desenvolvida neste capítulo demonstra que a concepção de um objeto de Inteligência Artificial, longe de ser um processo técnico neutro ou um ato de criação da própria 
máquina, é um ato profundamente humano, social e político. 
A partir do referencial teórico de Álvaro Vieira Pinto \cite{VieiraPinto2005}, foi estabelecido que a relação fundamental entre o ser humano 
e a tecnologia é a de um sujeito que, para satisfazer uma finalidade consciente, cria um objeto de mediação. 
No caso da IA, essa finalidade é inscrita não em comandos lógicos, 
mas em um complexo "roteiro" probabilístico, moldado pela curadoria de dados e pelo design da arquitetura do sistema. 

A narrativa de autonomia e inteligência da IA foi desmistificada, revelando-se como uma continuação ideológica da "tecno-estrutura", uma fachada que oculta tanto o locus real 
do poder, as corporações que detêm os meios de produção digital, quanto o trabalho humano massivo e precarizado que a sustenta. 
Contudo, a sociedade não é passiva. As 
respostas regulatórias e as lutas trabalhistas contemporâneas representam uma vigorosa reafirmação da agência humana, uma tentativa de restabelecer legal e socialmente as 
fronteiras entre o sujeito e o objeto. 

As implicações para a engenharia, que serão exploradas nos capítulos subsequentes, são profundas. 
Uma prática de engenharia consciente e crítica não pode se eximir de sua 
responsabilidade, escondendo-se atrás da suposta objetividade do artefato. 
Ela deve, ao contrário, reconhecer sua posição como agente no processo de concepção. 
Isso implica em 
questionar as finalidades que lhe são impostas, em tornar visível o trabalho humano que seus sistemas ocultam e em assumir a responsabilidade pela mediação que seus objetos 
criam no mundo. 
A engenharia de software não pode mais ser vista apenas como uma disciplina técnica, mas como uma prática criativa e intelectual que é impactada e, por vezes, 
limitada por modelos de gestão. 
As escolhas de arquitetura e processo não são neutras, elas estão inseridas em um sistema de produção com consequências diretas sobre as 
condições de trabalho de uma vasta cadeia de pessoas. 
A verdadeira "inteligência", como se argumentará, não reside no artefato, mas na consciência crítica do sujeito que o 
concebe e, fundamentalmente, na coletividade de sujeitos cujo trabalho o torna possível. 
Alinhar-se a uma engenharia centrada no humano, conforme a perspectiva de Vieira Pinto, 
significa assumir o papel de sujeito transformador, e não o de mero executor em uma linha de montagem industrial digital. 